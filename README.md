# WebLLM PWA (TypeScript) - ChatGPT mini UI

This project is a minimal PWA template that integrates WebLLM (CDN) and runs the heavy model work inside a Web Worker so the UI stays responsive on mobile (ROG Phone 6 recommended).

## Features
- TypeScript + React + Vite
- Web Worker for model init + inference
- PWA manifest & service worker (static asset caching)
- ChatGPT-like minimal UI optimized for mobile
- IndexedDB caching recommended (via WebLLM appConfig)

## How to run (quick)
1. Install:
   ```
   npm install
   ```
2. Run dev server:
   ```
   npm run dev
   ```
3. Open on PC or phone (use phone to test PWA / WebGPU). To debug, use Chrome remote devtools.

## Notes
- This template loads WebLLM from CDN inside the worker. Some browsers may block cross-origin ESM imports inside workers (CORS). If you see errors about loading the module in the worker:
  - Option A: Use Vite + npm (already configured) and import `@mlc-ai/web-llm` directly inside the worker; Vite will bundle it and avoid CORS.
  - Option B: Serve a local copy of the library or use bundling.

- The exact WebLLM API (method names) may change across releases. Open the browser console to inspect the `engine` object and adjust `engine.createChatCompletion` / `engine.request` calls accordingly.

## Files added
- index.html, manifest.webmanifest, sw.js
- src/* (React app, worker, storage)
- vite.config.ts, tsconfig.json, package.json

## Author
Generated by assistant. Feel free to modify and extend.
